{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fb40452ad5ae975fd33307735fd47c33f1aca999"
   },
   "source": [
    "## Basic Data Science and ML Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "478f0929dd095b53a8e89dcddf7f503dd11203ab"
   },
   "source": [
    "## OSEMN Pipeline \n",
    "* O - Obtaining our data\n",
    "* S - Scrubbing / Cleaning our data\n",
    "* E - Exploring / Visualizing our data will allow us to find patterns and trends\n",
    "* M - Modeling our data will give us our predictive power as a wizard\n",
    "* N - INterpreting our data\n",
    "\n",
    "\n",
    "For reference : https://www.linkedin.com/pulse/life-data-science-osemn-randy-lao/?lipi=urn%3Ali%3Apage%3Ad_flagship3_profile_view_base_post_details%3BmDlg5VsdSBCLBps2R0vRZA%3D%3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3977359aa7f65cc9d96fdf0ede4e99116fb314c6"
   },
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e19cd0e1959c38d52ed8c437b42f3ccd61e92fb4"
   },
   "source": [
    "## Basic EDA and statistical analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "650e7357fe6d26e6a557cc3088d9b1147b6093ea",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## gives information about the data types,columns, null value counts, memory usage etc\n",
    "## you can use pd_dataframe.info function here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4be617d9cdcb165ef3286163a22003877732ad0b"
   },
   "source": [
    "**DataFrame.describe()** method generates descriptive statistics that summarize the central tendency, dispersion and shape of a dataset’s distribution, excluding NaN values. This method tells us a lot of things about a dataset. One important thing is that the describe() method deals only with numeric values. It doesn't work with any categorical values. So if there are any categorical values in a column the describe() method will ignore it and display summary for the other columns unless parameter include=\"all\" is passed.\n",
    "\n",
    "Now, let's understand the statistics that are generated by the describe() method:\n",
    "* count tells us the number of NoN-empty rows in a feature.\n",
    "* mean tells us the mean value of that feature.\n",
    "* std tells us the Standard Deviation Value of that feature.\n",
    "* min tells us the minimum value of that feature.\n",
    "* 25%, 50%, and 75% are the percentile/quartile of each features. This quartile information helps us to detect Outliers.\n",
    "* max tells us the maximum value of that feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "0682a8c7acbdb75ad600df7b7cd732f4d5b0a17f"
   },
   "outputs": [],
   "source": [
    "## basic statistic details about the data (note only numerical columns would be displayed here unless parameter include=\"all\")\n",
    "## use pd_dataframe.describe() function to get summary of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1143fa069d6ff7b0c4decda62fa167a7a01b86a1"
   },
   "source": [
    "### The Question creeping out of this summary\n",
    "\n",
    "#### Can minimum value of below listed columns be zero (0)?\n",
    "\n",
    "On these columns, a value of zero does not make sense and thus indicates missing value.\n",
    "\n",
    "Following columns or variables have an invalid zero value:\n",
    "1. Glucose\n",
    "2. BloodPressure\n",
    "3. SkinThickness\n",
    "4. Insulin\n",
    "5. BMI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a5c66431403ac1246f52e4256b09b660fc273c25"
   },
   "source": [
    "#### It is better to replace zeros with nan since after that counting them would be easier and zeros need to be replaced with suitable values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "506fa58605d641694883cad75bb3683dafdb0356"
   },
   "outputs": [],
   "source": [
    "# count all nan values in each column for their proper handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "20bf4545b4d80cd00061d08d3cc2206d0b80f376"
   },
   "source": [
    "#### To fill these Nan values the data distribution needs to be understood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "d5ef22db6afea0d63189599fb4abbb2b3f53ccb5"
   },
   "outputs": [],
   "source": [
    "# Plot histograms of values of various features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "337635cc5b94f7bf6b1a95f5d4043e67604c2c8a"
   },
   "source": [
    "### Aiming to impute nan values for the columns in accordance with their distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "0568a737f6529e711d3e1ffa5493f0fa749efff3"
   },
   "outputs": [],
   "source": [
    "# replace NaN values by mean or any other suitable value\n",
    "# test your code for various values that can replace NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1bf99a7a106d92072207b4a5071098ac32c03902"
   },
   "source": [
    "## Plotting after Nan removal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "6b54f61be1a5b6fc75a90bfdcdfdb1df18a38594"
   },
   "outputs": [],
   "source": [
    "# Plot histograms after NaN are removed and observe changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fc09dd32d8cf836fd9afbb8f4d83d47260b89e91"
   },
   "source": [
    "## Skewness\n",
    "\n",
    "A ***left-skewed distribution*** has a long left tail. Left-skewed distributions are also called negatively-skewed distributions. That’s because there is a long tail in the negative direction on the number line. The mean is also to the left of the peak.\n",
    "\n",
    "A ***right-skewed distribution*** has a long right tail. Right-skewed distributions are also called positive-skew distributions. That’s because there is a long tail in the positive direction on the number line. The mean is also to the right of the peak.\n",
    "\n",
    "\n",
    "![](https://www.statisticshowto.datasciencecentral.com/wp-content/uploads/2014/02/pearson-mode-skewness.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "8322614f5de4888d713c0468a43ae2a3eb1b8862"
   },
   "outputs": [],
   "source": [
    "## observe the shape of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "c69e3cf2bce422520047daa7b02b688e42c197e4"
   },
   "outputs": [],
   "source": [
    "## data type analysis\n",
    "\n",
    "## Plot data type vs count of each datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "1d5a4e88b691d25e8c661e3e292f5d81d33c576e"
   },
   "outputs": [],
   "source": [
    "## null count analysis\n",
    "## use msnno (import missingno as msno) for null count analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "009e21b28bb9fcb64bd0b841d0aa09597b9bbea8"
   },
   "outputs": [],
   "source": [
    "## check the balance of the data by plotting the count of outcomes by their value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "87dc25ce0f9036237af2b8fb8560d7ba575df22c"
   },
   "source": [
    "#### Scatter matrix of uncleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "f100c23bcf63fa58180813ff594dfff591bb20ed"
   },
   "outputs": [],
   "source": [
    "## plot scatter matrix of uncleaned data for further analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a2503e0f31903aa2a3522f8c9e0771ea9aff7217"
   },
   "source": [
    "###### The pairs plot builds on two basic figures, the histogram and the scatter plot. The histogram on the diagonal allows us to see the distribution of a single variable while the scatter plots on the upper and lower triangles show the relationship (or lack thereof) between two variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "47a5993e4001d4ffc0ddf2dd59740045048ba738"
   },
   "source": [
    "#### Pair plot for clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "3adefc9ab47271b11f13687a245df6ced9f1b312"
   },
   "outputs": [],
   "source": [
    "## plot scatter matrix of uncleaned data for further analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "108b278e68021929a5c8cd186afc4848f1767986"
   },
   "source": [
    "***Pearson's Correlation Coefficient***: helps you find out the relationship between two quantities. It gives you the measure of the strength of association between two variables. The value of Pearson's Correlation Coefficient can be between -1 to +1. 1 means that they are highly correlated and 0 means no correlation.\n",
    "\n",
    "A heat map is a two-dimensional representation of information with the help of colors. Heat maps can help the user visualize simple or complex information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9dbea8e64dd833ce466c5d0585f4d8ad5bbfe8ff"
   },
   "source": [
    "#### Heatmap for unclean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "2971ad528058ac82e54eec7b42b814644cef4195"
   },
   "outputs": [],
   "source": [
    "## try plotting heatmap for unclean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a97ddd37b576e90c5cc192bd8ab46a4d44c960af"
   },
   "source": [
    "#### Heatmap for clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "0b000ace1a6558c57c0b485c66a5bdb84063174b"
   },
   "outputs": [],
   "source": [
    "## try plotting heatmap for unclean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5e5142438fcc7973b722337deb24ba2061e14316"
   },
   "source": [
    "## Scaling the data \n",
    "data Z is rescaled such that μ = 0 and 𝛔 = 1, and is done through this formula:\n",
    "![](https://cdn-images-1.medium.com/max/800/0*PXGPVYIxyI_IEHP7.)\n",
    "\n",
    "\n",
    "#### to learn more about scaling techniques\n",
    "https://medium.com/@rrfd/standardize-or-normalize-examples-in-python-e3f174b65dfc <br>\n",
    "https://machinelearningmastery.com/rescaling-data-for-machine-learning-in-python-with-scikit-learn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "2cf6c9ff22d3a7af35e399406e7565055ca6af36"
   },
   "outputs": [],
   "source": [
    "## use standard scaler to scale the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f87d51b88980792d54d8f3ba60c2c7b91d03cad3"
   },
   "source": [
    "## Test Train Split and Cross Validation methods\n",
    "\n",
    "\n",
    "\n",
    "***Train Test Split*** : To have unknown datapoints to test the data rather than testing with the same points with which the model was trained. This helps capture the model performance much better.\n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/1600/1*-8_kogvwmL1H6ooN1A1tsQ.png)\n",
    "\n",
    "***Cross Validation***: When model is split into training and testing it can be possible that specific type of data point may go entirely into either training or testing portion. This would lead the model to perform poorly. Hence over-fitting and underfitting problems can be well avoided with cross validation techniques\n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/1600/1*4G__SV580CxFj78o9yUXuQ.png)\n",
    "\n",
    "\n",
    "***About Stratify*** : Stratify parameter makes a split so that the proportion of values in the sample produced will be the same as the proportion of values provided to parameter stratify.\n",
    "\n",
    "For example, if variable y is a binary categorical variable with values 0 and 1 and there are 25% of zeros and 75% of ones, stratify=y will make sure that your random split has 25% of 0's and 75% of 1's.\n",
    "\n",
    "For Reference : https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "a7081050c51df07b8af1cd18c9be61f041a97fb8"
   },
   "outputs": [],
   "source": [
    "# Do train test split and train a Knn Model from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "ee126a72ca24e54ee78bfac94a21dfac1a3edee1"
   },
   "outputs": [],
   "source": [
    "## get train score\n",
    "## score that comes from testing on the same datapoints that were used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "8bbfda9d066c354f974dcb1180c3348aaa915c4e"
   },
   "outputs": [],
   "source": [
    "## get test score and optimal value of k\n",
    "## score that comes from testing on the datapoints that were split in the beginning to be used for testing solely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fe08768381ea8011d90ae58149c8e41b0a707da2"
   },
   "source": [
    "## Result Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "2a5c0b4fde15148a049fa340a58f5b4fa421e614"
   },
   "outputs": [],
   "source": [
    "## Plot train and test accuracy for various values of k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1db31455aba31edc524091fa0914743a284034c5"
   },
   "source": [
    "#### The best result is captured at k, then k should be used for the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "277c1bb9c48cca13536ac8ba71604818d323fae0"
   },
   "outputs": [],
   "source": [
    "## Setup a knn classifier with k neighbors\n",
    "## fit the model and calculate score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "22878f26662e0a863c48cf43030c9e6ab57d98fc"
   },
   "outputs": [],
   "source": [
    "## try to plot decision boundary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ab1e49d83f39a6ddc780c394d3a052b49508c6ac"
   },
   "source": [
    "# Model Performance Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0b471c49636c633d40442a208c5983d607e4fa2c"
   },
   "source": [
    "## 1. Confusion Matrix\n",
    "\n",
    "The confusion matrix is a technique used for summarizing the performance of a classification algorithm i.e. it has binary outputs.\n",
    "![](https://cdn-images-1.medium.com/max/1600/0*-GAP6jhtJvt7Bqiv.png)\n",
    "\n",
    "\n",
    "\n",
    "### ***In the famous cancer example***:\n",
    "\n",
    "\n",
    "###### Cases in which the doctor predicted YES (they have the disease), and they do have the disease will be termed as TRUE POSITIVES (TP). The doctor has correctly predicted that the patient has the disease.\n",
    "\n",
    "###### Cases in which the doctor predicted NO (they do not have the disease), and they don’t have the disease will be termed as TRUE NEGATIVES (TN). The doctor has correctly predicted that the patient does not have the disease.\n",
    "\n",
    "###### Cases in which the doctor predicted YES, and they do not have the disease will be termed as FALSE POSITIVES (FP). Also known as “Type I error”.\n",
    "\n",
    "###### Cases in which the doctor predicted NO, and they have the disease will be termed as FALSE NEGATIVES (FN). Also known as “Type II error”.\n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/1600/0*9r99oJ2PTRi4gYF_.jpg)\n",
    "\n",
    "For Reference: https://medium.com/@djocz/confusion-matrix-aint-that-confusing-d29e18403327"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "d09044f60af8405e7334c2062404336d0849e871"
   },
   "outputs": [],
   "source": [
    "## Get confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cb0b2fc2a33afeed856e2b3cc986ffb9e3e3ae7b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "893c30414255c296b13d0d421086bb1a24cdd22c"
   },
   "source": [
    "## 2. Classification Report\n",
    "\n",
    "Report which includes Precision, Recall and F1-Score.\n",
    "\n",
    "\n",
    "#### Precision Score\n",
    "        TP – True Positives\n",
    "        FP – False Positives\n",
    "\n",
    "        Precision – Accuracy of positive predictions.\n",
    "        Precision = TP/(TP + FP)\n",
    "        \n",
    "   \n",
    "#### Recall Score\n",
    "        FN – False Negatives\n",
    "\n",
    "        Recall(sensitivity or true positive rate): Fraction of positives that were correctly identified.\n",
    "        Recall = TP/(TP+FN)\n",
    "        \n",
    "#### F1 Score\n",
    "        F1 Score (aka F-Score or F-Measure) – A helpful metric for comparing two classifiers.\n",
    "        F1 Score takes into account precision and the recall. \n",
    "        It is created by finding the the harmonic mean of precision and recall.\n",
    "\n",
    "        F1 = 2 x (precision x recall)/(precision + recall)\n",
    "        \n",
    "        \n",
    "        \n",
    "> > ***Precision*** - Precision is the ratio of correctly predicted positive observations to the total predicted positive observations. The question that this metric answer is of all passengers that labeled as survived, how many actually survived? High precision relates to the low false positive rate. We have got 0.788 precision which is pretty good.\n",
    "> > \n",
    "> > Precision = TP/TP+FP\n",
    "> > \n",
    "> > ***Recall (Sensitivity)*** - Recall is the ratio of correctly predicted positive observations to the all observations in actual class - yes. The question recall answers is: Of all the passengers that truly survived, how many did we label? A recall greater than 0.5 is good.\n",
    "> > \n",
    "> > Recall = TP/TP+FN\n",
    "> > \n",
    "> > ***F1 score*** - F1 Score is the weighted average of Precision and Recall. Therefore, this score takes both false positives and false negatives into account. Intuitively it is not as easy to understand as accuracy, but F1 is usually more useful than accuracy, especially if you have an uneven class distribution. Accuracy works best if false positives and false negatives have similar cost. If the cost of false positives and false negatives are very different, it’s better to look at both Precision and Recall. \n",
    "> > \n",
    "> > F1 Score = 2*(Recall * Precision) / (Recall + Precision)\n",
    "        \n",
    "        \n",
    "For Reference: http://joshlawman.com/metrics-classification-report-breakdown-precision-recall-f1/\n",
    "                        : https://blog.exsilio.com/all/accuracy-precision-recall-f1-score-interpretation-of-performance-measures/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "6ac998149c1f0dd304b807707f0dc44dd2b2ffb3"
   },
   "outputs": [],
   "source": [
    "## find precision recall f1 score and support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7463f2aa317b5a0398aec869e94b168867ca0f0c"
   },
   "source": [
    "## 3. ROC - AUC\n",
    "ROC (Receiver Operating Characteristic) Curve tells us about how good the model can distinguish between two things (e.g If a patient has a disease or no). Better models can accurately distinguish between the two. Whereas, a poor model will have difficulties in distinguishing between the two\n",
    "\n",
    "\n",
    "Well Explained in this video: https://www.youtube.com/watch?v=OAl6eAyP-yo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "20b2083d2eaf2fca599eb6f2ef8803be0b1ac5d7"
   },
   "outputs": [],
   "source": [
    "## use roc_curve under sklearn's metrices to plot roc curve and also roc_auc_score to find area under ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "379eefad0181f1f57ffbb3634ab6d132af17464f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6c92773e49532f6133b23d511058202bb77ff2cd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "016a40668e45c0185ba011dc0f25f20512feabb3"
   },
   "source": [
    "# Hyper Parameter optimization\n",
    "Grid search is an approach to hyperparameter tuning that will methodically build and evaluate a model for each combination of algorithm parameters specified in a grid. \n",
    "\n",
    "Let’s consider the following example: \n",
    "\n",
    "Suppose, a machine learning model X takes hyperparameters a1, a2 and a3. In grid searching, you first define the range of values for each of the hyperparameters a1, a2 and a3. You can think of this as an array of values for each of the hyperparameters. Now the grid search technique will construct many versions of X with all the possible combinations of hyperparameter (a1, a2 and a3) values that you defined in the first place. This range of hyperparameter values is referred to as the grid. \n",
    "\n",
    "Suppose, you defined the grid as:\n",
    "a1 = [0,1,2,3,4,5]\n",
    "a2 = [10,20,30,40,5,60]\n",
    "a3 = [105,105,110,115,120,125]\n",
    "\n",
    "Note that, the array of values of that you are defining for the hyperparameters has to be legitimate in a sense that you cannot supply Floating type values to the array if the hyperparameter only takes Integer values.\n",
    "\n",
    "Now, grid search will begin its process of constructing several versions of X with the grid that you just defined.\n",
    "\n",
    "It will start with the combination of [0,10,105], and it will end with [5,60,125]. It will go through all the intermediate combinations between these two which makes grid search computationally very expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "e369c794253b71d3daa1444fb7d11872fb8a110c"
   },
   "outputs": [],
   "source": [
    "## use GridSearchCV\n",
    "## In case of classifier like knn the parameter to be tuned is n_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_uuid": "0899b30f7683581d675a185468972b2165eec04e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "875c731b163da4f47f8ec7bc27e33dfe92876e1c"
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
